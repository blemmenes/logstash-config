# logstash input from zeromq to filter
input { 
  zeromq {
    type => "pull-input"
    topology => "pushpull"
    address => ["tcp://192.168.48.101:5555","tcp://192.168.48.102:5555"]
    mode => "client"
    add_field => [ "filter_host", "{{ ansible_hostname }}" ]
  }
}

filter {
        # Filter to pull out priority and timestamp
  grok {
      type => "syslog"
      patterns_dir => [ "/opt/logstash/patterns" ]
      ####### Production #######
      pattern => [ "<%{POSINT:syslog_pri}>%{NUMBER:sequence_number}: %{IOSXR_LOCATION:iosxr_location}:%{IOS_SYSLOGTIMESTAMP:syslog_timestamp}\s:\s%{SYSLOGPROG}: %{GREEDYDATA:syslog_message}" ]
      pattern => [ "<%{POSINT:syslog_pri}>%{ASA_SYSLOGTIMESTAMP:syslog_timestamp}:%{GREEDYDATA:syslog_message}" ]
      pattern => [ "<%{POSINT:syslog_pri}>%{SYSLOGPROG}: %{DANSGUARDIAN_TIMESTAMP:syslog_timestamp}\s-\s%{GREEDYDATA:syslog_message}" ]
      ####### Production #######
      ####### Testing #######
      pattern => [ "<%{POSINT:syslog_pri}>%{NUMBER:sequence_number}: (?:%{NUMBER}: )?\*?%{IOS_SYSLOGTIMESTAMP:syslog_timestamp}: %{GREEDYDATA:syslog_message}" ]
      ####### Testing #######
      ####### Old #######
      #pattern => [ "<%{POSINT:syslog_pri}>%{SYSLOGPROG}: %{DANSGUARDIAN_TIMESTAMP:syslog_timestamp}%{GREEDYDATA:syslog_message}" ]
      #pattern => [ "<%{POSINT:syslog_pri}>%{SYSLOGTIMESTAMP:syslog_timestamp}:%{GREEDYDATA:syslog_message}" ]
      pattern => [ "<%{POSINT:syslog_pri}>%{SYSLOGPROG}: %{GREEDYDATA:syslog_message}" ]
      ####### Old #######
      add_field => [ "syslog_raw_message", "%{@message}" ]
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "received_from", "%{@source_host}" ]
  }
  syslog_pri {
      type => "syslog"
  }
  date {
      type => "syslog"
      syslog_timestamp => [ "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601", "MMM d yyyy HH:mm:ss", "yyyy.MM.dd H:mm:ss", "MMM dd HH:mm:ss.SSS", "MMM  d HH:mm:ss.SSS" ]
      #syslog_timestamp => [ "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601", "MMM d yyyy HH:mm:ss", "MMM dd HH:mm:ss.SSS" ]
  }
  mutate {
      type => "syslog"
      exclude_tags => "_grokparsefailure"
      #replace => [ "@source_host", "%{syslog_hostname}" ]
      replace => [ "@source_host", "%{@source_host}" ]
      replace => [ "@message", "%{syslog_message}" ]
  }
  mutate {
      type => "syslog"
      remove => [ "syslog_hostname", "syslog_message" ]
  }
}

################################### Grep Section ################################### 
#
# This section is used to catagorize and assign tags to events so that further
# grok sections can only be executed when needed (based on the type of log message)
#
# 'drop => "false"' is critical otherwise non-matching events will be discarded
#
################################### Grep Section ################################### 
filter {
  grep {
      type => "syslog"
      drop => "false"
      match => [ "@message", "\%ASA-" ]
      add_tag => "ASA"
  }
  grep {
      type => "syslog"
      drop => "false"
      match => [ "program", ".*dansguardian" ]
      add_tag => "dansguardian"
  }
  grep {
      type => "syslog"
      drop => "false"
      match => [ "program", ".*snort" ]
      add_tag => "snort"
  }
  grep {
      type => "syslog"
      drop => "false"
      tags => "ASA"
      match => [ "@message", ".*(?:U|u)ser" ]
      add_tag => "has_username"
  }
}
################################### Grep Section ################################### 

########################  ASA Section ########################  
filter {
        # filter for ASA message headers
  grok {
      tags => [ "ASA" ]
      patterns_dir => [ "/opt/logstash/patterns" ]
      pattern => [ "\%ASA-%{CISCO_SEVERITY:cisco_severity}-%{CISCO_MNEMONIC:cisco_mnemonic}:%{GREEDYDATA:message_remainder}" ]
      #add_tag => "got_ASA_header"
  }
  mutate {
      tags => [ "ASA" ]
      exclude_tags => "_grokparsefailure"
      replace => [ "@message", "%{message_remainder}" ]
  }
  mutate {
      tags => [ "ASA" ]
      exclude_tags => "_grokparsefailure"
      remove => [ "message_remainder" ]
  }
        # filter for ASA message headers
}

filter {
        # filter for ASA usernames
  grok {
      tags => [ "ASA", "has_username" ]
      patterns_dir => [ "/opt/logstash/patterns" ]
      pattern => [ "%{GREEDYDATA}(?:U|u)ser <%{USERNAME:username}>" ]
      pattern => [ "%{GREEDYDATA}(?:U|u)ser = %{USERNAME:username}" ]
      pattern => [ "%{GREEDYDATA}(?:U|u)name: %{USERNAME:username}" ]
      pattern => [ "%{GREEDYDATA}(?:U|u)sername = %{USERNAME:username}" ]
      pattern => [ "%{GREEDYDATA}(?:U|u)ser= %{USERNAME:username}" ]
      pattern => [ "%{GREEDYDATA}(?:U|u)ser %{QS:username}" ]
      add_field => [ "original_message", "%{@message}" ]
  }
  mutate {
      gsub => [
        "username", "\W", ""
      ]
  }
#  mutate {
#      tags => [ "ASA", "has_username" ]
#      exclude_tags => "_grokparsefailure"
#      replace => [ "@message", "%{original_message}" ]
#  }
  mutate {
      tags => [ "ASA", "has_username" ]
      exclude_tags => "_grokparsefailure"
#      remove => [ "original_message" ]
      remove_tag => [ "has_username" ]
  }
        # filter for ASA usernames
}

#filter {
#       # filter for ASA ip/ports?
#  grok {
#      tags => [ "ASA" ]
#      patterns_dir => [ "/opt/logstash/patterns" ]
#      pattern => [ "%{GREEDYDATA}%{HOSTPORT:hostport}>" ]
#      add_field => [ "original_message", "%{@message}" ]
#  }
#  mutate {
#      tags => [ "ASA" ]
#      exclude_tags => "_grokparsefailure"
#      replace => [ "@message", "%{original_message}" ]
#  }
#  mutate {
#      tags => [ "ASA" ]
#      exclude_tags => "_grokparsefailure"
#      remove => [ "original_message" ]
#  }
#       # filter for ASA usernames
#}
########################  ASA Section ######################## 


######################## dansguardian Section ########################  
filter {
        # filter for dansguardian proxy entries
  grok {
      tags => [ "dansguardian" ]
      patterns_dir => [ "/opt/logstash/patterns" ]
      pattern => [ "%{DANSGUARDIANLOG}%{GREEDYDATA:message_remainder}" ]
#      add_field => [ "original_message", "%{@message}" ]
  }
#  mutate {
#      tags => [ "dansguardian" ]
#      exclude_tags => "_grokparsefailure"
#      replace => [ "@message", "%{message_remainder}" ]
#  }
  mutate {
      tags => [ "dansguardian" ]
      exclude_tags => "_grokparsefailure"
#      remove => [ "original_message" ]
      remove_tag => [ "dansguardian" ]
  }
        # filter for dansguardian proxy entries
}
######################## dansguardian Section ######################## 

output { 
#  stdout { debug => true }
  #zeromq {
  #  topology => "pushpull"
  #  address => ["tcp://127.0.0.1:5556"]
  #  mode => "server"
  #}
  elasticsearch {
    cluster => "elasticsearch01"
  #  host => "127.0.0.1"
  #  host => "192.168.48.102"
  }
}
